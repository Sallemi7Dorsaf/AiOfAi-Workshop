{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bwM49m6iDVMw"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9LowN9YuDm10"},"outputs":[],"source":["! pip3 install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J-A1xmMZFyGq"},"outputs":[],"source":["import torch\n","\n","# Set the device to use\n","device = torch.device('cuda')\n","\n","# Enable GPU memory growth\n","torch.backends.cudnn.benchmark = True\n","torch.backends.cudnn.deterministic = True\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"aX9fzKgvexvW"},"source":["## Data Pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeuriFnKxPbr"},"outputs":[],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","device"]},{"cell_type":"markdown","metadata":{"id":"r0gkF02ne2eN"},"source":["### Read dataset file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEkyGmt9ew_u"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","train_filename = \"/content/drive/MyDrive/NLP Project/Datasets/Kaggle/trainkaggle.csv\"\n","test_filename = \"/content/drive/MyDrive/NLP Project/Datasets/Kaggle/testkaggle.csv\"\n","\n","df_train = pd.read_csv(train_filename)\n","df_test = pd.read_csv(test_filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V84HucEOgDOO"},"outputs":[],"source":["df_train.columns.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-e6m0sE3gAam"},"outputs":[],"source":["df_train = df_train.drop('Unnamed: 0', axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjyMLms3goJv"},"outputs":[],"source":["df_test = df_test.drop('Unnamed: 0', axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUgIlah0f3sl"},"outputs":[],"source":["df_train = df_train.rename(columns={'tweetText': 'text'})\n","df_test = df_test.rename(columns={'tweetText': 'text'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53eTEc5kfOz_"},"outputs":[],"source":["df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JqA9xC9rfRpu"},"outputs":[],"source":["df_test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KPaxol1hJ9u"},"outputs":[],"source":["df_train.loc[df_train.label == 'fake'].sample(10)"]},{"cell_type":"markdown","metadata":{"id":"Kcj-bcdphclF"},"source":["### Get the values of DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6YTKHXLhd-9"},"outputs":[],"source":["train_labels = df_train['label'].tolist()\n","train_text = df_train['text'].tolist()\n","\n","test_labels = df_test['label'].tolist()\n","test_text = df_test['text'].tolist()\n","\n","assert len(train_labels) == len(train_text)\n","assert len(test_labels) == len(test_text)\n","\n","print(\"len(train_text) = {}, len(test_text) = {}\".format(len(train_text), len(test_text)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9RDm6sNtcKU"},"outputs":[],"source":["def unique(list1):\n","\n","    # initialize a null list\n","    unique_list = []\n","\n","    # traverse for all elements\n","    for x in list1:\n","        # check if exists in unique_list or not\n","        if x not in unique_list:\n","            unique_list.append(x)\n","    # print list\n","    for x in unique_list:\n","        print (x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhhBCrdetrXd"},"outputs":[],"source":["unique(train_labels)"]},{"cell_type":"markdown","metadata":{"id":"6Ikq0WlZhlf2"},"source":["### Get values indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"omonifwzhm3t"},"outputs":[],"source":["def format_label_value(labels):\n","    \"\"\"\n","    Formats a list of labels to corresponding numeric values.\n","    \"\"\"\n","    format_label_list = []\n","\n","    for label in labels:\n","        if label == \"fake\":\n","            format_label_list.append(0)\n","        elif label == \"real\":\n","            format_label_list.append(1)\n","\n","\n","    return format_label_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeksG9jrhnDF"},"outputs":[],"source":["train_labels = format_label_value(train_labels)\n","test_labels = format_label_value(test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-H0j_3SphGl"},"outputs":[],"source":["len(train_labels)"]},{"cell_type":"markdown","metadata":{"id":"g2zYsu8ji94O"},"source":["## XLNet Tokenization & Input Formatting"]},{"cell_type":"markdown","metadata":{"id":"jZgbHzEWjBkV"},"source":["### XLNet Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGF2ZNspi_ad"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLNet tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GC07USgLjI8F"},"outputs":[],"source":["# Print the original sentence.\n","print('Original: ', train_text[0])\n","print(\"len(Original) = \", len(train_text[0]))\n","print(\"\\n\")\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(train_text[0]))\n","print(\"len(Tokenized) = \", len(tokenizer.tokenize(train_text[0])))\n","print(\"\\n\")\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_text[0])))\n","print(\"len(Token IDs) = \", len(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_text[0]))))\n","print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"qUSB6_d7jRZ-"},"source":["### Input Formatting for XLNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qseaBHhhjXP1"},"outputs":[],"source":["import logging\n","\n","# Set logger to avoid warning `token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512)`\n","logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n","\n","\n","def text_to_id(tokenizer, text_list):\n","    \"\"\"\n","    It is a function to transform text to id.\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    \"\"\"\n","    ids_list = []\n","\n","    for item in text_list:\n","        # Sentence to id and add [CLS] and [SEP]\n","        encoded_item = tokenizer.encode(item, add_special_tokens=True)\n","        ids_list.append(encoded_item)\n","\n","    return ids_list"]},{"cell_type":"code","source":["for i in range(len(train_text)):\n","    if not isinstance(train_text[i], str):\n","        train_text[i] = str(train_text[i])"],"metadata":{"id":"uqGR27iQoBIi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(test_text)):\n","    if not isinstance(test_text[i], str):\n","        test_text[i] = str(test_text[i])"],"metadata":{"id":"c1TSvKehoDT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wo_3-dACjaCd"},"outputs":[],"source":["train_text_ids = text_to_id(tokenizer, train_text)\n","test_text_ids = text_to_id(tokenizer, test_text)\n","\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: {}\\n'.format(train_text[0]))\n","print('Token IDs: {}\\n'.format(train_text_ids[0]))\n","print(\"len(train_text_ids) = {}\\n\".format(len(train_text_ids)))\n","print(\"len(test_text_ids) = {}\".format(len(test_text_ids)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oN56-W0njcje"},"outputs":[],"source":["print('Train: max sentence length: ', max([len(sen) for sen in train_text_ids]))\n","print('Train: Min sentence length: ', min([len(sen) for sen in train_text_ids]))\n","print('Test: max sentence length: ', max([len(sen) for sen in test_text_ids]))\n","print('Test: Min sentence length: ', min([len(sen) for sen in test_text_ids]))"]},{"cell_type":"markdown","metadata":{"id":"q44uZ0aZjf2F"},"source":["### Padding & Truncating"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iks7rmqWjhQt"},"outputs":[],"source":["def padding_truncating(input_ids_list, max_length):\n","    \"\"\"\n","    It is a function to perform padding and truncating\n","    @param input_ids_list: <List> text_ids\n","    @param max_length: <Integer> the number we wanna the sentence to be padding or truncating\n","    @return: processed input_ids_list\n","    \"\"\"\n","    processed_input_ids_list = []\n","    for item in input_ids_list:\n","        seq_list = []\n","\n","        if len(item) < max_length:\n","            # Define a seq_list with the length of max_length\n","            seq_list = [0] * (max_length - len(item))\n","            item = item + seq_list\n","\n","        elif len(item) >= max_length:\n","            item = item[:max_length]\n","\n","        processed_input_ids_list.append(item)\n","\n","    return processed_input_ids_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31KhABXxjlI-"},"outputs":[],"source":["train_padding_list = padding_truncating(train_text_ids, max_length=50)\n","test_padding_list = padding_truncating(test_text_ids, max_length=50)"]},{"cell_type":"markdown","metadata":{"id":"v4fbv5WYjnDV"},"source":["### Attention Masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gc7sfYfzjqnN"},"outputs":[],"source":["def get_attention_masks(pad_input_ids_list):\n","    \"\"\"\n","    It is a function to get attention masks:\n","\n","    - If a token ID is 0, then it's padding, set the mask to 0.\n","    - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    \"\"\"\n","    attention_masks_list = []\n","\n","    for item in pad_input_ids_list:\n","\n","        mask_list = []\n","        for subitem in item:\n","            if subitem > 0:\n","                mask_list.append(1)\n","            else:\n","                mask_list.append(0)\n","        attention_masks_list.append(mask_list)\n","\n","    return attention_masks_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGxUV0bOjsvF"},"outputs":[],"source":["train_attention_masks = get_attention_masks(train_padding_list)\n","test_attention_masks = get_attention_masks(test_padding_list)\n","\n","assert len(train_text) == len(train_labels) == len(train_attention_masks) == len(train_padding_list), \"Training data length mismatch\"\n","assert len(test_text) == len(test_labels) == len(test_attention_masks) == len(test_padding_list), \"Testing data length mismatch\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nlq4VcIjmVdY"},"outputs":[],"source":["print(len(train_text), len(train_labels), len(train_attention_masks), len(train_padding_list))\n"]},{"cell_type":"markdown","metadata":{"id":"h2JXnLzEjvQV"},"source":["### Split train dataset into train_dataset and validation_dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwR_A2n9j7Pu"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Use 90% for training and 10% for validation.\n","train_padding_list, validation_padding_list, train_labels, validation_labels, train_attention_masks, validation_attention_masks = train_test_split(train_padding_list, train_labels, train_attention_masks, random_state=2020, test_size=0.1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdfPWwAJqmFM"},"outputs":[],"source":["assert len(train_labels) == len(train_attention_masks) == len(train_padding_list)\n","assert len(validation_labels) == len(validation_attention_masks) == len(validation_padding_list)\n","assert len(test_labels) == len(test_attention_masks) == len(test_padding_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FYzCFgIUkMe-"},"outputs":[],"source":["print(\"len(train_labels) = {}\\nlen(validation_labels) = {}\\nlen(test_labels) = {}\".format(len(train_labels), len(validation_labels), len(test_labels)))\n"]},{"cell_type":"markdown","metadata":{"id":"vNVZasyOqpKU"},"source":["### Convert to Dataset"]},{"cell_type":"markdown","metadata":{"id":"9zf-Z_f2qtEF"},"source":["Convert all the List objects to tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUNOowY6qqt8"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","# Convert all inputs and labels into torch tensors, the required datatype for our model.\n","train_inputs = torch.tensor(train_padding_list)\n","validation_inputs = torch.tensor(validation_padding_list)\n","test_inputs = torch.tensor(test_padding_list)\n","\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","test_labels = torch.tensor(test_labels)\n","\n","train_masks = torch.tensor(train_attention_masks)\n","validation_masks = torch.tensor(validation_attention_masks)\n","test_masks = torch.tensor(test_attention_masks)"]},{"cell_type":"markdown","metadata":{"id":"vYZl4Z-Pqz6l"},"source":["Form the Dataset with torch.tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4v7nEriuwMqs"},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it\n","# here.\n","# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n","\n","batch_size = 16\n","\n","# Create the DataLoader for our training set.\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = RandomSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our test set.\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"51_c30ZrwPIz"},"source":["## Train XLNet Text Classification Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_r7_pM4wSZD"},"outputs":[],"source":["from transformers import XLNetForSequenceClassification, AdamW, LongformerConfig\n","import torch\n","\n","# Load BertForSequenceClassification, the pretrained BERT model\n","model = XLNetForSequenceClassification.from_pretrained(\n","    \"xlnet-base-cased\",  # Use the 12-layer BERT model, with an uncased vocab.\n","     num_labels = 2,      # The number of output labels -- 2 for binary classification.\n","                    # You can increase this for multi-class tasks.\n","     output_attentions = False, # Whether the model returns attentions weights.\n","     output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"zYh4m6yPwWLz"},"source":["### Optimizer & Learning Rate Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObLcx_iKwb1z"},"outputs":[],"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJSej39iwehr"},"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","print(\"total_steps = {}\".format(total_steps))\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"]},{"cell_type":"markdown","metadata":{"id":"wgpjWbSXwgis"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KK9AAdkawja8"},"outputs":[],"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuVnMQ29wlsz"},"outputs":[],"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1MoQRi0w0YE"},"outputs":[],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1AEQM1uMwqCc"},"outputs":[],"source":["import random\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 12345\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(epochs):\n","\n","    ##########################################\n","    #               Training                 #\n","    ##########################################\n","\n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to\n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 10 batches.\n","        if step % 10 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader.\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids\n","        #   [1]: attention masks\n","        #   [2]: labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Clear the gradients.\n","        model.zero_grad()\n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we have provided the `labels`.\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask,\n","                        labels=b_labels)\n","\n","        # The call to `model` always returns a tuple, so we need to pull the\n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n","        # `loss` is a Tensor containing a single value; the `.item()` function just returns the Python value from the tensor.\n","        total_loss += loss.item()\n","\n","        # Perform a `backward` pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)\n","\n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","\n","\n","    ##########################################\n","    #               Validation               #\n","    ##########################################\n","    # After the completion of each training epoch, measure our performance on our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n","    model.eval()\n","\n","    # Tracking variables\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","\n","        # Add batch to device\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():\n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here:\n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask)\n","\n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences.\n","        # flat_accuracy(y_pred, y_true)\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","\n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"]},{"cell_type":"markdown","metadata":{"id":"iw4ieJhewsi0"},"source":["### Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGH21EFSxj5E"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(loss_values, 'b-o')\n","\n","# Label the plot.\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"phqqQouzxmp8"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMndqCXFxotl"},"outputs":[],"source":["print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables\n","predictions, true_labels = [], []\n","\n","# Predict\n","total_correct = 0\n","for idx, batch in enumerate(test_dataloader):\n","\n","    print(\"Batch {}\".format(idx + 1))\n","\n","    # Add batch to device\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    # Telling the model not to compute or store gradients, saving memory and\n","    # speeding up prediction\n","    with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    # Get the prediction probability\n","    logits = outputs[0]\n","\n","    # Get the prediction label\n","    pred = torch.argmax(logits, dim=1)\n","\n","    # Get the number of correct predictions in this batch\n","    batch_correct = (pred == b_labels).sum().item()\n","    print(\"Batch correct = {}\\n\".format(batch_correct))\n","\n","    # Accumulate the number of correct predictions over all batches\n","    total_correct += batch_correct\n","\n","    # Append the predicted labels and true labels for this batch\n","    predictions.append(pred.cpu().numpy())\n","    true_labels.append(b_labels.cpu().numpy())\n","\n","\n","print('DONE.')\n","print(\"Total correct = \", total_correct)\n","print(\"Test accuracy = {0:.2f}\".format(total_correct / len(test_inputs)))\n","\n","# Concatenate the predicted labels and true labels over all batches\n","predictions = np.concatenate(predictions, axis=0)\n","true_labels = np.concatenate(true_labels, axis=0)\n","\n","# Print classification report and confusion matrix\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","print(classification_report(true_labels, predictions))\n","print(confusion_matrix(true_labels, predictions))"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","toc_visible":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}