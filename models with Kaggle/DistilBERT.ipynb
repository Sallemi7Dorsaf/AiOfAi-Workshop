{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1604,"status":"ok","timestamp":1682546878179,"user":{"displayName":"dorsaf sallemi","userId":"11081128056738234729"},"user_tz":240},"id":"qgkQ3HlFC97M","outputId":"0a623fd5-72a8-49ae-bc8d-0fea000cc2df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12010,"status":"ok","timestamp":1682546890186,"user":{"displayName":"dorsaf sallemi","userId":"11081128056738234729"},"user_tz":240},"id":"1D6-iGuADEkC","outputId":"70e60ff5-dfa0-4b22-e2a2-8f630b24ed32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"]}],"source":["! pip3 install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMaFJHD1C5W6"},"outputs":[],"source":["import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1940,"status":"ok","timestamp":1682546892123,"user":{"displayName":"dorsaf sallemi","userId":"11081128056738234729"},"user_tz":240},"id":"yFSjX6AIC5W8","outputId":"ff140de0-2420-4404-f1c4-aa0e9ec56b40"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a8ed244a-1d49-4d4c-a0f6-442fb9121703\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>tweetText</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>36335</td>\n","      <td>anyone actually believe possible Barack Hussei...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12384</td>\n","      <td>Two law enforcement officials Utah resort area...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>24419</td>\n","      <td>8 brutal years race-baiting, endless stories v...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>24740</td>\n","      <td>BEIRUT (Reuters) Iranian military vessel confr...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>27039</td>\n","      <td>Elizabeth Warren went attack Donald Trump Sund...</td>\n","      <td>fake</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8ed244a-1d49-4d4c-a0f6-442fb9121703')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a8ed244a-1d49-4d4c-a0f6-442fb9121703 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a8ed244a-1d49-4d4c-a0f6-442fb9121703');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Unnamed: 0                                          tweetText label\n","0       36335  anyone actually believe possible Barack Hussei...  fake\n","1       12384  Two law enforcement officials Utah resort area...  fake\n","2       24419  8 brutal years race-baiting, endless stories v...  fake\n","3       24740  BEIRUT (Reuters) Iranian military vessel confr...  real\n","4       27039  Elizabeth Warren went attack Donald Trump Sund...  fake"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('/content/drive/MyDrive/NLP Project/Datasets/Kaggle/trainkaggle.csv')\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682546892123,"user":{"displayName":"dorsaf sallemi","userId":"11081128056738234729"},"user_tz":240},"id":"py3DF1XqC5W9","outputId":"7d51f954-c551-4606-c98f-3f6416fac8bb"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-43307ae0-f51b-40d2-b1a0-1437f754ea5d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>tweetText</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22216</td>\n","      <td>WASHINGTON (Reuters) U.S. Defense Secretary Ji...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27917</td>\n","      <td>SAO PAULO (Reuters) Brazilian federal Judge rg...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25007</td>\n","      <td>Tune Alternate Current Radio Network (ACR) ano...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1377</td>\n","      <td>COST OBAMAPHONE PROGRAM WENT 50%. WHY:REMEMBER...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>32476</td>\n","      <td>NEW YORK (Reuters) New York City Mayor Bill de...</td>\n","      <td>real</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43307ae0-f51b-40d2-b1a0-1437f754ea5d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-43307ae0-f51b-40d2-b1a0-1437f754ea5d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-43307ae0-f51b-40d2-b1a0-1437f754ea5d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Unnamed: 0                                          tweetText label\n","0       22216  WASHINGTON (Reuters) U.S. Defense Secretary Ji...  real\n","1       27917  SAO PAULO (Reuters) Brazilian federal Judge rg...  real\n","2       25007  Tune Alternate Current Radio Network (ACR) ano...  fake\n","3        1377  COST OBAMAPHONE PROGRAM WENT 50%. WHY:REMEMBER...  fake\n","4       32476  NEW YORK (Reuters) New York City Mayor Bill de...  real"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["test = pd.read_csv('/content/drive/MyDrive/NLP Project/Datasets/Kaggle/testkaggle.csv')\n","test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIs7S7W7C5W9"},"outputs":[],"source":["#encode output\n","label_mapping = {'fake': 1, 'real': 0}\n","train.label = train.label.map(label_mapping)\n","test.label = test.label.map(label_mapping)"]},{"cell_type":"markdown","metadata":{"id":"TNfjE8aGC5W9"},"source":["### Train val split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvmzkXWqC5W9"},"outputs":[],"source":["train = train.dropna()\n","test = test.dropna()\n","X_train, X_val, y_train, y_val = train_test_split(train['tweetText'], train['label'], test_size=0.2, random_state=42)\n","X_test, y_test = test['tweetText'], test.label"]},{"cell_type":"markdown","metadata":{"id":"mwnsMwTSC5W9"},"source":["#### Preprocessing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iswcQaB7C5W-"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuDtaQGvC5W-"},"outputs":[],"source":["X_train_encoded = tokenizer(\n","    list(X_train.values),\n","    padding=True,\n","    truncation=True,\n","    return_tensors='pt'\n",")\n","X_val_encoded = tokenizer(\n","    list(X_val.values),\n","    padding=True,\n","    truncation=True,\n","    return_tensors='pt'\n",")\n","X_test_encoded = tokenizer(\n","    list(X_test),\n","    padding=True,\n","    truncation=True,\n","    return_tensors='pt'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTBw5DCwC5W-"},"outputs":[],"source":["class FakeNewsDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zcxTjMiC5W-"},"outputs":[],"source":["train_dataset = FakeNewsDataset(X_train_encoded, y_train.values)\n","val_dataset = FakeNewsDataset(X_val_encoded, y_val.values)\n","test_dataset = FakeNewsDataset(X_test_encoded, y_test.values)\n","train_loader = DataLoader(train_dataset, batch_size=32)\n","val_loader = DataLoader(val_dataset, batch_size=32)\n","test_loader = DataLoader(test_dataset, batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"CwKxU-CGC5W-"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6350,"status":"ok","timestamp":1682546979826,"user":{"displayName":"dorsaf sallemi","userId":"11081128056738234729"},"user_tz":240},"id":"IByCXSZlElvQ","outputId":"fdcf305e-451c-4fd6-ec95-97efd2128130"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.11.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.27.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.14.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.4.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"]}],"source":["pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7Vodbj9C5W_"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification\n","import evaluate\n","import numpy as np\n","import os\n","os.environ['HF_MLFLOW_LOG_ARTIFACTS'] = \"1\" # save models as artifact for the expirment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l74L4Q4TC5W_"},"outputs":[],"source":["def compute_metrics(eval_preds):\n","    metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2137,"status":"ok","timestamp":1682546981953,"user":{"displayName":"dorsaf sallemi","userId":"11081128056738234729"},"user_tz":240},"id":"hMEywybXC5W_","outputId":"810d97ce-27fa-49ad-9bf7-ff502cebea01"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/NLP Project/saved_models/distilbert/',          # output directory\n","    num_train_epochs=5,              # total number of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=8,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=400,\n","    evaluation_strategy='steps',\n","    eval_steps=400,\n","    load_best_model_at_end=True,\n","    save_total_limit=3,\n","    save_steps=400\n","\n",")\n","\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=val_dataset,             # evaluation dataset\n","    compute_metrics=compute_metrics\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":958},"id":"9E7EvwxnC5W_","outputId":"09cee2e3-b796-412d-f80c-59aed0bad2df"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='9907' max='17960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 9907/17960 2:00:00 < 1:37:33, 1.38 it/s, Epoch 2.76/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>400</td>\n","      <td>0.162600</td>\n","      <td>0.049151</td>\n","      <td>0.990116</td>\n","      <td>0.990639</td>\n","      <td>0.981452</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.011200</td>\n","      <td>0.043419</td>\n","      <td>0.994988</td>\n","      <td>0.995229</td>\n","      <td>0.991027</td>\n","      <td>0.999468</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.021700</td>\n","      <td>0.024535</td>\n","      <td>0.996102</td>\n","      <td>0.996284</td>\n","      <td>0.993646</td>\n","      <td>0.998935</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.025300</td>\n","      <td>0.011767</td>\n","      <td>0.997076</td>\n","      <td>0.997212</td>\n","      <td>0.994703</td>\n","      <td>0.999734</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.012300</td>\n","      <td>0.004621</td>\n","      <td>0.999304</td>\n","      <td>0.999335</td>\n","      <td>0.999202</td>\n","      <td>0.999468</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.012000</td>\n","      <td>0.007097</td>\n","      <td>0.999165</td>\n","      <td>0.999201</td>\n","      <td>0.999201</td>\n","      <td>0.999201</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.002900</td>\n","      <td>0.013708</td>\n","      <td>0.998608</td>\n","      <td>0.998668</td>\n","      <td>0.999733</td>\n","      <td>0.997604</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.002800</td>\n","      <td>0.005399</td>\n","      <td>0.999025</td>\n","      <td>0.999068</td>\n","      <td>0.999201</td>\n","      <td>0.998935</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.004400</td>\n","      <td>0.008865</td>\n","      <td>0.998886</td>\n","      <td>0.998935</td>\n","      <td>0.999201</td>\n","      <td>0.998669</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.003200</td>\n","      <td>0.013843</td>\n","      <td>0.998469</td>\n","      <td>0.998537</td>\n","      <td>0.998138</td>\n","      <td>0.998935</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.010600</td>\n","      <td>0.067206</td>\n","      <td>0.990394</td>\n","      <td>0.990739</td>\n","      <td>0.999188</td>\n","      <td>0.982433</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.014500</td>\n","      <td>0.038860</td>\n","      <td>0.995684</td>\n","      <td>0.995859</td>\n","      <td>0.999464</td>\n","      <td>0.992281</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.009900</td>\n","      <td>0.005127</td>\n","      <td>0.999443</td>\n","      <td>0.999468</td>\n","      <td>0.999202</td>\n","      <td>0.999734</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.000000</td>\n","      <td>0.005464</td>\n","      <td>0.999443</td>\n","      <td>0.999468</td>\n","      <td>0.999202</td>\n","      <td>0.999734</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.000000</td>\n","      <td>0.005714</td>\n","      <td>0.999443</td>\n","      <td>0.999468</td>\n","      <td>0.999202</td>\n","      <td>0.999734</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.000000</td>\n","      <td>0.005939</td>\n","      <td>0.999443</td>\n","      <td>0.999468</td>\n","      <td>0.999202</td>\n","      <td>0.999734</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.014700</td>\n","      <td>0.007956</td>\n","      <td>0.998747</td>\n","      <td>0.998801</td>\n","      <td>0.999467</td>\n","      <td>0.998137</td>\n","    </tr>\n","    <tr>\n","      <td>7200</td>\n","      <td>0.008700</td>\n","      <td>0.014693</td>\n","      <td>0.998329</td>\n","      <td>0.998402</td>\n","      <td>0.999200</td>\n","      <td>0.997604</td>\n","    </tr>\n","    <tr>\n","      <td>7600</td>\n","      <td>0.006500</td>\n","      <td>0.008541</td>\n","      <td>0.998886</td>\n","      <td>0.998935</td>\n","      <td>0.998935</td>\n","      <td>0.998935</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.000000</td>\n","      <td>0.009706</td>\n","      <td>0.998886</td>\n","      <td>0.998935</td>\n","      <td>0.998935</td>\n","      <td>0.998935</td>\n","    </tr>\n","    <tr>\n","      <td>8400</td>\n","      <td>0.000000</td>\n","      <td>0.007800</td>\n","      <td>0.999165</td>\n","      <td>0.999201</td>\n","      <td>0.999467</td>\n","      <td>0.998935</td>\n","    </tr>\n","    <tr>\n","      <td>8800</td>\n","      <td>0.006300</td>\n","      <td>0.011120</td>\n","      <td>0.998608</td>\n","      <td>0.998668</td>\n","      <td>0.999467</td>\n","      <td>0.997871</td>\n","    </tr>\n","    <tr>\n","      <td>9200</td>\n","      <td>0.001000</td>\n","      <td>0.011617</td>\n","      <td>0.998886</td>\n","      <td>0.998935</td>\n","      <td>0.999201</td>\n","      <td>0.998669</td>\n","    </tr>\n","    <tr>\n","      <td>9600</td>\n","      <td>0.000000</td>\n","      <td>0.012085</td>\n","      <td>0.998886</td>\n","      <td>0.998935</td>\n","      <td>0.999201</td>\n","      <td>0.998669</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","<ipython-input-27-14c0bc9f7485>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"X5n-nuC6C5XA"},"source":["### Calculate performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5JXdxjz5vUP"},"outputs":[],"source":["eval_result = trainer.evaluate(eval_dataset=val_dataset)\n","\n","# Print the evaluation results\n","print(\"Evaluation results:\")\n","for key, value in eval_result.items():\n","    print(f\"{key}: {value:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MH2tW_-p6biN"},"outputs":[],"source":["eval_result = trainer.evaluate(eval_dataset=test_dataset)\n","\n","# Print the evaluation results\n","print(\"Evaluation results:\")\n","for key, value in eval_result.items():\n","    print(f\"{key}: {value:.4f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"nlp_project","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"a7481d9fdbdb5bc3cfa1c41a158e56f79c2803b01a0eeac01b32455c6569565e"}}},"nbformat":4,"nbformat_minor":0}